{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set matplotlib color cycle\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0.1,0.9,6))\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=viridis_colors)\n",
    "\n",
    "# Set matplotlib color map\n",
    "mpl.rc('image', cmap='viridis')\n",
    "\n",
    "# Set rand state\n",
    "rand_seed = 6021023\n",
    "\n",
    "# Set parallelism parameters: note xgb_jobs * optimization_jobs should\n",
    "# be at least one less than the number of avalible threads\n",
    "xgb_jobs = 5\n",
    "optimization_jobs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's load up the data and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   city                    50000 non-null  object \n",
      " 1   trips_in_first_30_days  50000 non-null  int64  \n",
      " 2   signup_date             50000 non-null  object \n",
      " 3   avg_rating_of_driver    41878 non-null  float64\n",
      " 4   avg_surge               50000 non-null  float64\n",
      " 5   last_trip_date          50000 non-null  object \n",
      " 6   phone                   49604 non-null  object \n",
      " 7   surge_pct               50000 non-null  float64\n",
      " 8   ultimate_black_user     50000 non-null  bool   \n",
      " 9   weekday_pct             50000 non-null  float64\n",
      " 10  avg_dist                50000 non-null  float64\n",
      " 11  avg_rating_by_driver    49799 non-null  float64\n",
      "dtypes: bool(1), float64(6), int64(1), object(4)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_json('./ultimate_data_challenge.json')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat, we can see we have missing data in the avg_rating_of_driver, phone and avg_rating_by_driver columns. Let's take a look at the data in those columns and make some decisions about how to handle the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>41878.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>49799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.278200</td>\n",
       "      <td>4.601559</td>\n",
       "      <td>1.074764</td>\n",
       "      <td>8.849536</td>\n",
       "      <td>60.926084</td>\n",
       "      <td>5.796827</td>\n",
       "      <td>4.778158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.792684</td>\n",
       "      <td>0.617338</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>19.958811</td>\n",
       "      <td>37.081503</td>\n",
       "      <td>5.707357</td>\n",
       "      <td>0.446652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.700000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.940000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>160.960000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trips_in_first_30_days  avg_rating_of_driver     avg_surge  \\\n",
       "count            50000.000000          41878.000000  50000.000000   \n",
       "mean                 2.278200              4.601559      1.074764   \n",
       "std                  3.792684              0.617338      0.222336   \n",
       "min                  0.000000              1.000000      1.000000   \n",
       "25%                  0.000000              4.300000      1.000000   \n",
       "50%                  1.000000              4.900000      1.000000   \n",
       "75%                  3.000000              5.000000      1.050000   \n",
       "max                125.000000              5.000000      8.000000   \n",
       "\n",
       "          surge_pct   weekday_pct      avg_dist  avg_rating_by_driver  \n",
       "count  50000.000000  50000.000000  50000.000000          49799.000000  \n",
       "mean       8.849536     60.926084      5.796827              4.778158  \n",
       "std       19.958811     37.081503      5.707357              0.446652  \n",
       "min        0.000000      0.000000      0.000000              1.000000  \n",
       "25%        0.000000     33.300000      2.420000              4.700000  \n",
       "50%        0.000000     66.700000      3.880000              5.000000  \n",
       "75%        8.600000    100.000000      6.940000              5.000000  \n",
       "max      100.000000    100.000000    160.960000              5.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both avg. rating columns range from 1 to 5. Let's assume a missing value means that no rating was given. In this case we will assign a zero so we do not loose these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['avg_rating_of_driver'] = data['avg_rating_of_driver'].fillna(0)\n",
    "data['avg_rating_by_driver'] = data['avg_rating_by_driver'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>last_trip_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>ultimate_black_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>King's Landing</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>15.4</td>\n",
       "      <td>True</td>\n",
       "      <td>46.2</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Astapor</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Astapor</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>King's Landing</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2014-06-29</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Winterfell</td>\n",
       "      <td>14</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>Android</td>\n",
       "      <td>11.8</td>\n",
       "      <td>False</td>\n",
       "      <td>82.4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  trips_in_first_30_days signup_date  avg_rating_of_driver  \\\n",
       "0  King's Landing                       4  2014-01-25                   4.7   \n",
       "1         Astapor                       0  2014-01-29                   5.0   \n",
       "2         Astapor                       3  2014-01-06                   4.3   \n",
       "3  King's Landing                       9  2014-01-10                   4.6   \n",
       "4      Winterfell                      14  2014-01-27                   4.4   \n",
       "\n",
       "   avg_surge last_trip_date    phone  surge_pct  ultimate_black_user  \\\n",
       "0       1.10     2014-06-17   iPhone       15.4                 True   \n",
       "1       1.00     2014-05-05  Android        0.0                False   \n",
       "2       1.00     2014-01-07   iPhone        0.0                False   \n",
       "3       1.14     2014-06-29   iPhone       20.0                 True   \n",
       "4       1.19     2014-03-15  Android       11.8                False   \n",
       "\n",
       "   weekday_pct  avg_dist  avg_rating_by_driver  \n",
       "0         46.2      3.67                   5.0  \n",
       "1         50.0      8.26                   5.0  \n",
       "2        100.0      0.77                   5.0  \n",
       "3         80.0      2.36                   4.9  \n",
       "4         82.4      3.13                   4.9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phone column contains a string for IPhone / Android. In this case let's assign 'Unknown' to empty values again so as not to loose those observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['phone'] = data['phone'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now it's time to think about retention - the description is a little bit ambiguous. The data describes a 'cohort of users who signed up for an Ultimate account in\n",
    "January 2014. The data was pulled several months later; we consider a user retained if they\n",
    "were “active” (i.e. took a trip) in the preceding 30 days.' However, the actual date that the data was pulled is not mentioned, therefore is is unclear what date range the preceding 30 days encompases.\n",
    "\n",
    "I will use a simplifying assumption here - there are 50,000 observations over timespan of just 182 days. Therefore, we will assume that there is at least on trip each day and use the most recent trip date in the dataset as the 'current date' or the date the data was pulled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns to datetime\n",
    "data['signup_date'] = pd.to_datetime(data['signup_date'])\n",
    "data['last_trip_date'] = pd.to_datetime(data['last_trip_date'])\n",
    "\n",
    "# get data pull date\n",
    "data_pull_date = data['last_trip_date'].max()\n",
    "\n",
    "# add catagorical retention column\n",
    "data['retained'] = 0\n",
    "data.loc[(data_pull_date - data['last_trip_date']).dt.days <= 30, 'retained'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent retention: 37.6%\n"
     ]
    }
   ],
   "source": [
    "# Calculate percent retained\n",
    "retained_count = int(data['retained'].sum())\n",
    "not_retained_count = int(len(data) - retained_count)\n",
    "percent_retained = (retained_count / (retained_count + not_retained_count)) * 100\n",
    "\n",
    "print(f'Percent retention: {np.round(percent_retained, 1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get set up to build our predictive model. We want to predict whether or not a user will still be active 6 mo. after they first signed up. Let's try formalizing the question as a binary classification - yes still active or no, not still active.\n",
    "\n",
    "First step will be to add a feature called activity_deltaT - the time in days between signup and last trip. We can then threshold this feature at 150 days and encode to binary. If the user has activity after 150 days, that means they were active in their sixth month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['activity_deltaT'] = (data['last_trip_date'] - data['signup_date']).dt.days\n",
    "data['six_months_active'] = 0\n",
    "data.loc[data['activity_deltaT'] >= 150, 'six_months_active'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent still active after 6 mo.: 25.4%\n"
     ]
    }
   ],
   "source": [
    "# Calculate percent still active after 6 mo.\n",
    "active_count = int(data['six_months_active'].sum())\n",
    "not_active_count = int(len(data) - active_count)\n",
    "percent_active = (active_count / (active_count + not_active_count)) * 100\n",
    "\n",
    "print(f'Percent still active after 6 mo.: {np.round(percent_active, 1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up - one hot encoding of categorical features: city and phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode_columns(data: 'DataFrame', col_names: list) -> 'DataFrame':\n",
    "    '''One hot encode one or more columns\n",
    "    \n",
    "    takes data frame and list of features to one hot encode. Returns dataframe\n",
    "    with features onehot encoded, original featuer columns are dropped.'''\n",
    "    \n",
    "    for col_name in col_names:\n",
    "        # make onehot encoder\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "        # extract target column\n",
    "        feature_array = np.array(data[col_name]).reshape(-1, 1)\n",
    "\n",
    "        # onehot encode\n",
    "        onehot_array = onehot_encoder.fit_transform(feature_array).astype('int32')\n",
    "\n",
    "        # convert one hot encoded months to dataframe\n",
    "        onehot_df = pd.DataFrame(onehot_array)\n",
    "        onehot_df.columns = onehot_encoder.get_feature_names()\n",
    "        onehot_df.columns = onehot_df.columns.str.replace('x0_', '')\n",
    "\n",
    "        # concatenat onehot encoded feature back to original dataframe\n",
    "        data = pd.concat([data, onehot_df], axis = 1)\n",
    "\n",
    "        # drop column we just onehotted\n",
    "        data.drop(col_name, axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = onehot_encode_columns(data, ['city', 'phone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimate_black_user is also a categorical column but it is boolean, so we will handle it differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['encoded_ultimate_black_user'] = 0\n",
    "data.loc[data['ultimate_black_user'] == True, 'encoded_ultimate_black_user'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to to train an XGBoost model to classify users as 'retained' or 'not retained'. But first, we need to remove the 'signup_data' and 'last_trip_date' columns since XGBoost can't handle dates. Let's also clean up some dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['signup_date', 'last_trip_date', 'retained', 'activity_deltaT'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "int32_features = [\n",
    "    'trips_in_first_30_days', \n",
    "    'six_months_active',\n",
    "    'ultimate_black_user'\n",
    "]\n",
    "\n",
    "float32_features = [\n",
    "    'avg_rating_of_driver',\n",
    "    'avg_surge',\n",
    "    'surge_pct',\n",
    "    'weekday_pct',\n",
    "    'avg_dist',\n",
    "    'avg_rating_by_driver'\n",
    "]\n",
    "\n",
    "\n",
    "data[int32_features] = data[int32_features].astype('int32')\n",
    "data[float32_features] = data[float32_features].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, here is the wrangled and ready data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   trips_in_first_30_days       50000 non-null  int32  \n",
      " 1   avg_rating_of_driver         50000 non-null  float32\n",
      " 2   avg_surge                    50000 non-null  float32\n",
      " 3   surge_pct                    50000 non-null  float32\n",
      " 4   ultimate_black_user          50000 non-null  int32  \n",
      " 5   weekday_pct                  50000 non-null  float32\n",
      " 6   avg_dist                     50000 non-null  float32\n",
      " 7   avg_rating_by_driver         50000 non-null  float32\n",
      " 8   six_months_active            50000 non-null  int32  \n",
      " 9   Astapor                      50000 non-null  int32  \n",
      " 10  King's Landing               50000 non-null  int32  \n",
      " 11  Winterfell                   50000 non-null  int32  \n",
      " 12  Android                      50000 non-null  int32  \n",
      " 13  Unknown                      50000 non-null  int32  \n",
      " 14  iPhone                       50000 non-null  int32  \n",
      " 15  encoded_ultimate_black_user  50000 non-null  int64  \n",
      "dtypes: float32(6), int32(9), int64(1)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>ultimate_black_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "      <th>six_months_active</th>\n",
       "      <th>Astapor</th>\n",
       "      <th>King's Landing</th>\n",
       "      <th>Winterfell</th>\n",
       "      <th>Android</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>iPhone</th>\n",
       "      <th>encoded_ultimate_black_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "      <td>46.200001</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>8.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.14</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>2.36</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0</td>\n",
       "      <td>82.400002</td>\n",
       "      <td>3.13</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trips_in_first_30_days  avg_rating_of_driver  avg_surge  surge_pct  \\\n",
       "0                       4                   4.7       1.10       15.4   \n",
       "1                       0                   5.0       1.00        0.0   \n",
       "2                       3                   4.3       1.00        0.0   \n",
       "3                       9                   4.6       1.14       20.0   \n",
       "4                      14                   4.4       1.19       11.8   \n",
       "\n",
       "   ultimate_black_user  weekday_pct  avg_dist  avg_rating_by_driver  \\\n",
       "0                    1    46.200001      3.67                   5.0   \n",
       "1                    0    50.000000      8.26                   5.0   \n",
       "2                    0   100.000000      0.77                   5.0   \n",
       "3                    1    80.000000      2.36                   4.9   \n",
       "4                    0    82.400002      3.13                   4.9   \n",
       "\n",
       "   six_months_active  Astapor  King's Landing  Winterfell  Android  Unknown  \\\n",
       "0                  0        0               1           0        0        0   \n",
       "1                  0        1               0           0        1        0   \n",
       "2                  0        1               0           0        0        0   \n",
       "3                  1        0               1           0        0        0   \n",
       "4                  0        0               0           1        1        0   \n",
       "\n",
       "   iPhone  encoded_ultimate_black_user  \n",
       "0       1                            1  \n",
       "1       0                            0  \n",
       "2       1                            0  \n",
       "3       1                            1  \n",
       "4       0                            0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(['Active after 6 mo.', 'Not active after 6 mo.'])\n",
    "Y = data['six_months_active']\n",
    "X = data.drop(['six_months_active'], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.values, Y.values, random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(\n",
    "    known_params,\n",
    "    param_dist, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    num_jobs, \n",
    "    search_iterations, \n",
    "    search_scoring_func\n",
    "):\n",
    "\n",
    "    # initalize XGBoost classifier\n",
    "    xgb_mod = XGBClassifier(**known_params)\n",
    "\n",
    "    # set up random search\n",
    "    xgb_random_search = RandomizedSearchCV(\n",
    "        xgb_mod, \n",
    "        param_distributions=param_dist,\n",
    "        scoring=search_scoring_func,\n",
    "        n_iter=search_iterations,\n",
    "        n_jobs=num_jobs\n",
    "    )\n",
    "\n",
    "    # run and time search\n",
    "    start = time()\n",
    "    xgb_best_model = xgb_random_search.fit(x_train, y_train)\n",
    "    print(\"RandomizedSearchCV took %.f min. for %d candidate\"\n",
    "          \" parameter settings.\" % (((time() - start)/60), search_iterations))\n",
    "    \n",
    "    return xgb_best_model, xgb_random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 9 min. for 100 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "# run random parameter search with XGBoost classifier, keep best model\n",
    "# and results from all parameter settings tried\n",
    "search_iterations = 100\n",
    "search_scoring_func = search_scoring_func = make_scorer(matthews_corrcoef)\n",
    "\n",
    "known_params = {\n",
    "    'random_state': rand_seed,\n",
    "    'n_estimators': 200,\n",
    "    'n_jobs': xgb_jobs\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'class_weight': loguniform(0.0001, 10),\n",
    "    'learning_rate': loguniform(0.001, 0.1)\n",
    "}\n",
    "\n",
    "xgb_best_model, xgb_random_search = tune_hyperparameters(\n",
    "    known_params,\n",
    "    param_dist, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    optimization_jobs, \n",
    "    search_iterations, \n",
    "    search_scoring_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score and show confusion matrix\n",
    "def print_model_score(model, x_train, y_train, x_test, y_test):\n",
    "    training_score = matthews_corrcoef(model.predict(x_train), y_train)\n",
    "    test_score = matthews_corrcoef(model.predict(x_test), y_test)\n",
    "    \n",
    "    display_markdown('**Matthews correlation coeff., training set: {}**'.format(np.round(training_score, 2)), raw=True)\n",
    "    display_markdown('**Matthews correlation coeff., test set: {}**'.format(np.round(test_score, 2)), raw=True)\n",
    "\n",
    "    \n",
    "def display_confusion_matrix(model, class_names, x_test, y_test):\n",
    "\n",
    "    raw_cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "    print(\"Raw count confusion matrix\")\n",
    "    print(raw_cm)\n",
    "    \n",
    "    normalized_cm = plot_confusion_matrix(model, x_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "\n",
    "    normalized_cm.ax_.set_title(\"Normalized confusion matrix\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized class_weight: 0.183\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'param_n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/ultimate_takehome/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4409\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4410\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4411\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9b58622adecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimized class_weight: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_search_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimized num estimators: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ultimate_takehome/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ultimate_takehome/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4416\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4417\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4419\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4420\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ultimate_takehome/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4402\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4404\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'param_n_estimators'"
     ]
    }
   ],
   "source": [
    "rand_search_results = pd.DataFrame(xgb_random_search.cv_results_).dropna()\n",
    "\n",
    "class_weight = rand_search_results.iloc[0]['param_class_weight']\n",
    "print(\"Optimized class_weight: {}\".format(np.round(class_weight, 3)))\n",
    "\n",
    "n_estimators = rand_search_results.iloc[0]['param_n_estimators']\n",
    "print(\"Optimized num estimators: {}\".format(int(n_estimators)))\n",
    "\n",
    "learning_rate = rand_search_results.iloc[0]['param_learning_rate']\n",
    "print(\"Optimized learning rate: {}\".format(np.round(learning_rate, 3)))\n",
    "\n",
    "# score and show confusion matrix\n",
    "print_model_score(xgb_best_model, x_train, y_train, x_test, y_test)\n",
    "display_confusion_matrix(xgb_best_model, class_names, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    n_jobs=(xgb_jobs * optimization_jobs), \n",
    "    random_state=rand_seed,\n",
    "    scale_pos_weight=2.9,\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score and show confusion matrix\n",
    "print_model_score(xgb_model, x_train, y_train, x_test, y_test)\n",
    "display_confusion_matrix(xgb_model, class_names, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = np.array(list(X))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "# plt.rc('axes', titlesize=30)     # fontsize of the axes title\n",
    "# plt.rc('axes', labelsize=30)    # fontsize of the x and y labels\n",
    "# plt.rc('xtick', labelsize=15)    # fontsize of the tick labels\n",
    "# plt.rc('ytick', labelsize=25)    # fontsize of the tick labels\n",
    "plt.title(\"Feature importance\")\n",
    "plt.bar(range(x_test.shape[1]), importances[indices],\n",
    "       color=\"darkblue\", align=\"center\")\n",
    "plt.xticks(np.arange(len(indices)), feature_names[indices], rotation='vertical')\n",
    "plt.xlim([-1, x_test.shape[1]])\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Relative importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
